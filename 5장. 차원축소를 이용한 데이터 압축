4장에서는 여러 가지 특성 선택 방식을 사용하여 데이터셋의 차원을 축소하는 방법을 배움
차원 축소를 위한 특성 선택의 또 다른 방식은 특성 추출임
차원 축소는 원본 데이터셋을 좀 더 낮은 차원의 새로운 특성 부분 공간으로 변환함

1. 주성분 분석(PCA)을 사용한 비지도 데이터 압축하기
2. 지도 방식의 차원 축소 방법인 선형 판별 북선(LDA) 이용하여 클래스 구별 능력 최대화하기
3. 커널 PCA를 사용한 비선형 차원 축소하기

5.1 주성분 분석을 통한 비지도 차원 축소
특성 선택과 특성 추출의 차이는 원본 특성을 유지하느냐에 달라짐
순차 후진 선택과 같은 특성 선택 알고리즘은 원본 특성을 유지하지만 특성 추출은 새로운 특성 공간으로 데이터를 변환하거나 투영함

차원 축소 관점에서 보면 특성 추출은 대부분의 관련 있는 정보를 유지하면서 데이터를 압축하는 방법으로 이해할 수 있음
저장공간을 절약하거나 학습 알고리즘의 계산 효율성을 향상할 뿐만 아니라 차원의 저주 문제를 감소시켜 예측 성능을 향상하기도 함(특히 규제가 없는 모델에서!)

5.1.1 주성분 분석의 주요 단계(비지도 선형 변환 기법)
- 특성 추출과 차원 축소 용도로 많은 분야에서 널리 쓰임
- 탐색적 데이터 분석, 주식 거래 시장의 잡음 제거, 생물정보학 분야에서 게놈 데이터나 유전자 발현 분석 등이 있음

특성 사이의 상관관계를 기반으로 하여 데이터에 있는 특성을 잡아낼 수 있음
고차원 데이터에서 분산이 가장 큰 방향을 찾고 좀 더 작거나 같은 수의 차원을 갖는 새로운 부분 공간으로 투영함
새로운 부분 공간의 직교 좌표는 주어진 조건하에서 분산이 최대인 방향으로 해석할 수 있음. 새로운 특성 축과 직각을 이룸!

원본 d차원 데이터를 새로운 k차원의 부분 공간으로 변환ㄴ하여 만들어진 첫번째 주성분이 가장 큰 분산을 가짐
모든 주성분은 다른 주성분과 사오간관계가 없다는(직교한다는) 가정하에 가장 큰 분산을 가짐. 
입력 특성에 상관관계가 있더라도 만들어진 주성분은 서로 수직을 이룬다면 상관관계가 상관없음.
PCA방향은 데이터 스케일에 매우 민감하므로 모든 특성의 중요도를 동일하게 취급하려면 PCA를 적용하기 전에 표준화 전처리를 해야함

1. d차원 데이터셋을 표준화 전처리함
2. 공분산 행렬을 만듦
3. 공분산 행렬을 고유 벡터와 고유값으로 분해
4. 고윳값을 내림차순으로 정렬하고 그에 해당하는 고유 벡터의 순위를 매김
5. 고윳값이 가장 큰 k개의 고유 벡터를 선택함. 여기서 k는 새로운 특성 부분 공간의 차원임
6. 최상위 k개의 고유 벡터로 투영 행렬 W를 만듦
7. 투영 행렬 W를 사용해 d차원 입력 데이터셋 X를 새로운 k차원의 특성 부분 공간으로 변환함

5.1.2 주성분 추출 단계
1. 데이터를 표준화 전처리함
2. 공분산 행렬을 구성함
3. 공분산 행렬의 고윳값과 고유 벡터를 구함
4. 고유값을 내림차순으로 정렬하여 고유 벡터의 순위를 매김


5.1.3 총분산과 설명된 분산

 


